{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f85d7015-9411-45d1-bc94-8892097f5ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import struct\n",
    "import zlib\n",
    "from pynbt import NBTFile\n",
    "import io\n",
    "import os\n",
    "import math\n",
    "\n",
    "\n",
    "def translate_chunk_location(x, z, h_offset):\n",
    "    # Calculate the chunk coordinates\n",
    "    c_x = h_offset % 32\n",
    "    c_z = h_offset // 32\n",
    "\n",
    "    # Now, `offset` is the location of the chunk's data in the file,\n",
    "    # and `x` and `z` are the chunk's coordinates within this region.\n",
    "    # print(f\"Chunk at [{x}({c_x}), {z}({c_z})] has an offset of {h_offset}\")\n",
    "    x_min = (x * 16) + (c_x * 16)\n",
    "    x_max = (x * 16) + (c_x * 16) + 16\n",
    "    z_min = (z * 16) + (c_z * 16)\n",
    "    z_max = (z * 16) + (c_z * 16) + 16\n",
    "\n",
    "    # print(f\"Chunk covers [{x_min}, {z_min}] [{x_min}, {z_max}] [{x_max}, {z_min}] [{x_max}, {z_max}]\")\n",
    "\n",
    "    return c_x, c_z\n",
    "\n",
    "\n",
    "def get_chunk_offset_and_length(header, i):\n",
    "    # Extract the four bytes for this chunk entry\n",
    "    entry_bytes = header[i * 4: i * 4 + 4]\n",
    "\n",
    "    # The first three bytes are the offset (big-endian)\n",
    "    offset = int.from_bytes(entry_bytes[:3], 'big')\n",
    "\n",
    "    # The fourth byte is the length\n",
    "    length = entry_bytes[3]\n",
    "\n",
    "    return offset, length\n",
    "    \n",
    "\n",
    "def read_region_file(filepath):\n",
    "    # Get the filename from path.\n",
    "    filename = filepath.split('/')[-1]\n",
    "\n",
    "    # Filename format is r.x.z.mca\n",
    "    filesplit = filename.split('.')\n",
    "\n",
    "    # X and Z coords are parts 1 and 2 of the filename.\n",
    "    x = int(filesplit[1])\n",
    "    z = int(filesplit[2])\n",
    "    \n",
    "    chunks = {}\n",
    "    filename = f'data/region/r.{x}.{z}.mca'\n",
    "    with open(filename, 'rb') as file:\n",
    "        # Region files begin with an 8192 byte header\n",
    "        header = file.read(8192)\n",
    "\n",
    "        # locations (1024 entries)\n",
    "        for i in range(0, 1024):\n",
    "            offset, length = get_chunk_offset_and_length(header, i)\n",
    "            \n",
    "            if offset == 0 and length == 0:\n",
    "                continue  # Chunk is not present\n",
    "                \n",
    "            # Convert the offset to bytes (multiply by 4096)\n",
    "            offset *= 4096\n",
    "\n",
    "            # check past offset\n",
    "            file.seek(0, 2)  # end to of file\n",
    "            if file.tell() < offset: \n",
    "                # offset is past file, no chunk exists\n",
    "                continue\n",
    "\n",
    "            # goto offset and read \n",
    "            file.seek(offset)\n",
    "            chunk_header = file.read(5)  # Read chunk length and compression type\n",
    "            if len(chunk_header) < 5:\n",
    "                print(f\"Incomplete chunk header for chunk {i}.\")\n",
    "                continue\n",
    "\n",
    "            chunk_length, compression_type = struct.unpack('>IB', chunk_header)\n",
    "            chunk_length -= 1  # Subtract the compression type byte\n",
    "\n",
    "            # Read and decompress the chunk data\n",
    "            compressed_chunk_data = file.read(chunk_length)\n",
    "            if len(compressed_chunk_data) < chunk_length:\n",
    "                print(f\"Incomplete chunk data for chunk {i}.\")\n",
    "                continue\n",
    "\n",
    "            \n",
    "            chunks[translate_chunk_location(x, z, i)] = zlib.decompress(compressed_chunk_data)\n",
    "            # chunks[(x, z, i)] = zlib.decompress(compressed_chunk_data)\n",
    "    return chunks\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d39805f-f5a0-4242-95c0-24387bd43f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_chunk(the_chunk):\n",
    "    # convert to bytes to io stream and read\n",
    "    chunk_data = io.BytesIO(the_chunk)\n",
    "    nbt = NBTFile(chunk_data)\n",
    "    \n",
    "    \n",
    "    #print(nbt.pretty())\n",
    "    \n",
    "    for idx, section in enumerate(nbt['sections']):\n",
    "        print(section['Y'])\n",
    "        # print(section['biomes'].pretty())\n",
    "        # print(section['block_states'].pretty())\n",
    "        # print(section['block_states']['data'])\n",
    "        print(section['block_states']['palette'])\n",
    "        block_palette_size = len(section['block_states']['palette'])\n",
    "        print(block_palette_size)\n",
    "        # for bio_pal in section['biomes']['palette']:\n",
    "        #     print(f\"biome={bio_pal}\")\n",
    "        #     # print(section['biomes']['palette'])\n",
    "        # for block_states in section['block_states']:\n",
    "        #     print(block_states.pretty())\n",
    "        #     print(block_states['data'].pretty())\n",
    "            # print(block_type['name'])\n",
    "        # print(\"------\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21fb81b2-ed15-4003-bcf3-11111202b6af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r.-1.-1.mca\n",
      "Loaded 288 chunks.\n",
      "r.-1.0.mca\n",
      "Loaded 142 chunks.\n",
      "r.-2.-1.mca\n",
      "Loaded 209 chunks.\n",
      "r.-2.0.mca\n",
      "Loaded 117 chunks.\n"
     ]
    }
   ],
   "source": [
    "fnames = os.listdir('data/region/')\n",
    "\n",
    "all_chunks = {}\n",
    "\n",
    "for fname in fnames:\n",
    "    print(fname)\n",
    "    file_chunks = read_region_file(f'data/region/{fname}')\n",
    "    print(f\"Loaded {len(file_chunks)} chunks.\")\n",
    "    all_chunks.update(file_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67b368bd-669a-4e6f-a98c-621f8ee83aae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TAG_Byte(-4, 'Y')\n",
      "TAG_List(8 entries, 'palette')\n",
      "8\n",
      "TAG_Byte(-3, 'Y')\n",
      "TAG_List(6 entries, 'palette')\n",
      "6\n",
      "TAG_Byte(-2, 'Y')\n",
      "TAG_List(8 entries, 'palette')\n",
      "8\n",
      "TAG_Byte(-1, 'Y')\n",
      "TAG_List(8 entries, 'palette')\n",
      "8\n",
      "TAG_Byte(0, 'Y')\n",
      "TAG_List(16 entries, 'palette')\n",
      "16\n",
      "TAG_Byte(1, 'Y')\n",
      "TAG_List(23 entries, 'palette')\n",
      "23\n",
      "TAG_Byte(2, 'Y')\n",
      "TAG_List(11 entries, 'palette')\n",
      "11\n",
      "TAG_Byte(3, 'Y')\n",
      "TAG_List(17 entries, 'palette')\n",
      "17\n",
      "TAG_Byte(4, 'Y')\n",
      "TAG_List(23 entries, 'palette')\n",
      "23\n",
      "TAG_Byte(5, 'Y')\n",
      "TAG_List(14 entries, 'palette')\n",
      "14\n",
      "TAG_Byte(6, 'Y')\n",
      "TAG_List(1 entries, 'palette')\n",
      "1\n",
      "TAG_Byte(7, 'Y')\n",
      "TAG_List(1 entries, 'palette')\n",
      "1\n",
      "TAG_Byte(8, 'Y')\n",
      "TAG_List(1 entries, 'palette')\n",
      "1\n",
      "TAG_Byte(9, 'Y')\n",
      "TAG_List(1 entries, 'palette')\n",
      "1\n",
      "TAG_Byte(10, 'Y')\n",
      "TAG_List(1 entries, 'palette')\n",
      "1\n",
      "TAG_Byte(11, 'Y')\n",
      "TAG_List(1 entries, 'palette')\n",
      "1\n",
      "TAG_Byte(12, 'Y')\n",
      "TAG_List(1 entries, 'palette')\n",
      "1\n",
      "TAG_Byte(13, 'Y')\n",
      "TAG_List(1 entries, 'palette')\n",
      "1\n",
      "TAG_Byte(14, 'Y')\n",
      "TAG_List(1 entries, 'palette')\n",
      "1\n",
      "TAG_Byte(15, 'Y')\n",
      "TAG_List(1 entries, 'palette')\n",
      "1\n",
      "TAG_Byte(16, 'Y')\n",
      "TAG_List(1 entries, 'palette')\n",
      "1\n",
      "TAG_Byte(17, 'Y')\n",
      "TAG_List(1 entries, 'palette')\n",
      "1\n",
      "TAG_Byte(18, 'Y')\n",
      "TAG_List(1 entries, 'palette')\n",
      "1\n",
      "TAG_Byte(19, 'Y')\n",
      "TAG_List(1 entries, 'palette')\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "read_chunk(all_chunks[(3, 26)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709f638a-f0f3-4f63-ad71-ed20b530c8a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
